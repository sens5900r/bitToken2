% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bitToken.R
\name{bitToken}
\alias{bitToken}
\title{Tokenize text data in a data frame}
\usage{
bitToken(
  data,
  text_column,
  filter_var = NULL,
  filter_vals = NULL,
  lengths = FALSE
)
}
\arguments{
\item{data}{A data frame containing the text data to tokenize}

\item{text_column}{The name of the column in \code{data} containing the text data to tokenize}

\item{filter_var}{The name of a column in \code{data} to filter on (optional)}

\item{filter_vals}{A vector of values to filter on in \code{filter_var} (optional)}

\item{lengths}{A logical value indicating whether to return the lengths of the tokens (default = FALSE)}
}
\value{
A list of token vectors or a vector of token lengths
}
\description{
This function tokenizes text data in a specified column of a data frame.
The resulting tokens are returned as a list or, optionally, as a vector of token lengths.
Filtering options are also available to allow the user to filter the data frame based on specific values.
}
\examples{
\dontrun{
library(bitToken2)
data(chatGPT_news1)
tokens <- bitToken(data = chatGPT_news1, text_column = "title")
head(tokens)
token_lengths <- bitToken(data = chatGPT_news1, text_column = "title", lengths=TRUE)
}

}
\seealso{
\code{\link[stringr]{str_split}} for more information on string splitting
}
\keyword{text}
\keyword{tokenizing}
